{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from capsnet import CapsNet\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data/')\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "tf.random.set_random_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "checkpoint_file = './tmp/model.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "def count_params():\n",
    "    size = lambda v: functools.reduce(lambda x, y: x*y, v.get_shape().as_list())\n",
    "    n_trainable = sum(size(v) for v in tf.trainable_variables())\n",
    "    print(\"Model size (Trainable): {:.1f}M\\n\".format(n_trainable/1000000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, restore = False, n_epochs = 50):\n",
    "    init = tf.global_variables_initializer()\t\n",
    "\n",
    "    n_iter_train_per_epoch = mnist.train.num_examples // batch_size\n",
    "    n_iter_valid_per_epoch = mnist.validation.num_examples // batch_size\n",
    "\n",
    "    best_loss_val = np.infty\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        writer = tf.summary.FileWriter(\"output\", sess.graph)\n",
    "\n",
    "        if restore and tf.train.checkpoint_exists('checkpoint_file'):\n",
    "            saver.restore(sess, checkpoint_file)\n",
    "        else:\n",
    "            init.run()\n",
    "\n",
    "        print('\\n\\nRunning CapsNet ...\\n')\n",
    "        count_params()\n",
    "\n",
    "        print(\"\\nt_loss : training loss\")\n",
    "        print(\"t_ml   : training margin loss\")\n",
    "        print(\"t_rl   : training reconstruction loss\")\n",
    "        print(\"v_loss : validation loss\")\n",
    "        print(\"t_acc  : training accuracy\")\n",
    "        print(\"v_acc  : validation accuracy\\n\")\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            loss_train_ep = []\n",
    "            margin_loss_train_ep = []\n",
    "            recnst_loss_train_ep = []\n",
    "            acc_train_ep  = []\n",
    "            for it in range(1, n_iter_train_per_epoch + 1):\n",
    "                X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "\n",
    "                _, loss_batch_train, margin_loss_train, recnst_loss_train, acc_batch_train = sess.run(\n",
    "                                [model.train_op, \n",
    "                                 model.batch_loss, \n",
    "                                 model.margn_loss,\n",
    "                                 model.recnst_loss_scale,\n",
    "                                 model.accuracy],\n",
    "                                feed_dict = {model.X: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                                                model.y: y_batch,\n",
    "                                                model.reconstruction: True})\n",
    "\n",
    "                print(\"\\rIter: {}/{} [{:.1f}%] loss : {:.5f}\".format(\n",
    "                    it, n_iter_train_per_epoch, 100.0 * it / n_iter_train_per_epoch, loss_batch_train), end=\"\")\n",
    "\n",
    "                loss_train_ep.append(loss_batch_train)\n",
    "                margin_loss_train_ep.append(margin_loss_train)\n",
    "                recnst_loss_train_ep.append(recnst_loss_train)\n",
    "                acc_train_ep.append(acc_batch_train)\n",
    "                \n",
    "            loss_train = np.mean(loss_train_ep)\n",
    "            margin_loss_train = np.mean(margin_loss_train_ep)\n",
    "            recnst_loss_train = np.mean(recnst_loss_train_ep)\n",
    "            acc_train = np.mean(acc_train_ep)\n",
    "            \n",
    "            loss_val_ep = []\n",
    "            acc_val_ep  = []\n",
    "\n",
    "            for it in range(1, n_iter_valid_per_epoch + 1):\n",
    "                X_batch, y_batch = mnist.validation.next_batch(batch_size)\n",
    "                loss_batch_val, acc_batch_val = sess.run(\n",
    "                                [model.batch_loss, model.accuracy],\n",
    "                                feed_dict = {model.X_cropped: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                                                model.y: y_batch})\n",
    "\n",
    "                loss_val_ep.append(loss_batch_val)\n",
    "                acc_val_ep.append(acc_batch_val)\n",
    "\n",
    "                print(\"\\rValidation {}/{} {:.1f}%\".format(it, n_iter_valid_per_epoch, 100.0 * it / n_iter_valid_per_epoch), end=\" \"*30)\n",
    "\n",
    "            loss_val = np.mean(loss_val_ep)\n",
    "            acc_val  = np.mean(acc_val_ep)\n",
    "            \n",
    "            print(\"\\rep: {3d} t_loss: {:.5f}, t_ml: {:.5f}, t_rl: {:.5f}, v_loss: {:.5f}, t_acc: {:.4f}%, v_acc: {:.4f}% {}\".format(\n",
    "                epoch + 1, \n",
    "                loss_train, \n",
    "                margin_loss_train,\n",
    "                recnst_loss_train,\n",
    "                loss_val, \n",
    "                acc_train * 100.0, \n",
    "                acc_val * 100.0, \n",
    "                \"(imp)\" if loss_val < best_loss_val else \"\"))\n",
    "\n",
    "            if loss_val < best_loss_val:\n",
    "                best_loss_val = loss_val\n",
    "            saver.save(sess, checkpoint_file)\n",
    "            \n",
    "\n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CapsNet(rounds = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Running CapsNet ...\n",
      "\n",
      "Model size (Trainable): 8.2M\n",
      "\n",
      "epoch: 1 loss_train: 0.15213, margin_loss: 0.12496, recnst_loss: 0.02717, loss_val: 0.04223, train_acc: 86.3327%, valid_acc: 98.4600% (imp)\n",
      "epoch: 2 loss_train: 0.04533, margin_loss: 0.02245, recnst_loss: 0.02288, loss_val: 0.03299, train_acc: 98.2255%, valid_acc: 98.8200% (imp)\n",
      "epoch: 3 loss_train: 0.03630, margin_loss: 0.01568, recnst_loss: 0.02062, loss_val: 0.02831, train_acc: 98.7236%, valid_acc: 99.0800% (imp)\n",
      "epoch: 4 loss_train: 0.03059, margin_loss: 0.01190, recnst_loss: 0.01869, loss_val: 0.02663, train_acc: 99.0455%, valid_acc: 99.1600% (imp)\n",
      "epoch: 5 loss_train: 0.02768, margin_loss: 0.01030, recnst_loss: 0.01738, loss_val: 0.02410, train_acc: 99.2127%, valid_acc: 99.1600% (imp)\n",
      "epoch: 6 loss_train: 0.02453, margin_loss: 0.00854, recnst_loss: 0.01599, loss_val: 0.02095, train_acc: 99.3491%, valid_acc: 99.3600% (imp)\n",
      "epoch: 7 loss_train: 0.02260, margin_loss: 0.00761, recnst_loss: 0.01499, loss_val: 0.02062, train_acc: 99.4454%, valid_acc: 99.4000% (imp)\n",
      "epoch: 8 loss_train: 0.02066, margin_loss: 0.00674, recnst_loss: 0.01392, loss_val: 0.01825, train_acc: 99.5073%, valid_acc: 99.3800% (imp)\n",
      "epoch: 9 loss_train: 0.01912, margin_loss: 0.00596, recnst_loss: 0.01315, loss_val: 0.01817, train_acc: 99.5745%, valid_acc: 99.4200% (imp)\n",
      "epoch: 10 loss_train: 0.01771, margin_loss: 0.00533, recnst_loss: 0.01238, loss_val: 0.01638, train_acc: 99.6418%, valid_acc: 99.4600% (imp)\n",
      "epoch: 11 loss_train: 0.01683, margin_loss: 0.00492, recnst_loss: 0.01191, loss_val: 0.01587, train_acc: 99.6745%, valid_acc: 99.4200% (imp)\n",
      "epoch: 12 loss_train: 0.01590, margin_loss: 0.00449, recnst_loss: 0.01141, loss_val: 0.01562, train_acc: 99.7073%, valid_acc: 99.4600% (imp)\n",
      "epoch: 13 loss_train: 0.01505, margin_loss: 0.00399, recnst_loss: 0.01106, loss_val: 0.01508, train_acc: 99.7545%, valid_acc: 99.4800% (imp)\n",
      "epoch: 14 loss_train: 0.01475, margin_loss: 0.00397, recnst_loss: 0.01078, loss_val: 0.01492, train_acc: 99.7182%, valid_acc: 99.5000% (imp)\n",
      "epoch: 15 loss_train: 0.01390, margin_loss: 0.00346, recnst_loss: 0.01044, loss_val: 0.01397, train_acc: 99.7673%, valid_acc: 99.5400% (imp)\n",
      "epoch: 16 loss_train: 0.01341, margin_loss: 0.00322, recnst_loss: 0.01018, loss_val: 0.01387, train_acc: 99.8018%, valid_acc: 99.4800% (imp)\n",
      "epoch: 17 loss_train: 0.01292, margin_loss: 0.00294, recnst_loss: 0.00998, loss_val: 0.01349, train_acc: 99.8309%, valid_acc: 99.5400% (imp)\n",
      "epoch: 18 loss_train: 0.01249, margin_loss: 0.00277, recnst_loss: 0.00973, loss_val: 0.01326, train_acc: 99.8345%, valid_acc: 99.4600% (imp)\n",
      "epoch: 19 loss_train: 0.01211, margin_loss: 0.00258, recnst_loss: 0.00953, loss_val: 0.01307, train_acc: 99.8327%, valid_acc: 99.5800% (imp)\n",
      "epoch: 20 loss_train: 0.01174, margin_loss: 0.00240, recnst_loss: 0.00934, loss_val: 0.01272, train_acc: 99.8655%, valid_acc: 99.5800% (imp)\n",
      "epoch: 21 loss_train: 0.01149, margin_loss: 0.00224, recnst_loss: 0.00924, loss_val: 0.01250, train_acc: 99.8709%, valid_acc: 99.6000% (imp)\n",
      "epoch: 22 loss_train: 0.01120, margin_loss: 0.00211, recnst_loss: 0.00909, loss_val: 0.01228, train_acc: 99.8873%, valid_acc: 99.5200% (imp)\n",
      "epoch: 23 loss_train: 0.01114, margin_loss: 0.00208, recnst_loss: 0.00906, loss_val: 0.01203, train_acc: 99.8873%, valid_acc: 99.5800% (imp)\n",
      "epoch: 24 loss_train: 0.01077, margin_loss: 0.00191, recnst_loss: 0.00886, loss_val: 0.01212, train_acc: 99.8909%, valid_acc: 99.5400% \n",
      "epoch: 25 loss_train: 0.01069, margin_loss: 0.00187, recnst_loss: 0.00882, loss_val: 0.01194, train_acc: 99.8982%, valid_acc: 99.5800% (imp)\n",
      "epoch: 26 loss_train: 0.01059, margin_loss: 0.00182, recnst_loss: 0.00877, loss_val: 0.01194, train_acc: 99.9036%, valid_acc: 99.5400% \n",
      "epoch: 27 loss_train: 0.01050, margin_loss: 0.00179, recnst_loss: 0.00870, loss_val: 0.01181, train_acc: 99.9054%, valid_acc: 99.6000% (imp)\n",
      "epoch: 28 loss_train: 0.01020, margin_loss: 0.00164, recnst_loss: 0.00856, loss_val: 0.01165, train_acc: 99.9036%, valid_acc: 99.5800% (imp)\n",
      "epoch: 29 loss_train: 0.01030, margin_loss: 0.00171, recnst_loss: 0.00858, loss_val: 0.01157, train_acc: 99.9109%, valid_acc: 99.5400% (imp)\n",
      "epoch: 30 loss_train: 0.01006, margin_loss: 0.00155, recnst_loss: 0.00851, loss_val: 0.01166, train_acc: 99.9146%, valid_acc: 99.6000% \n"
     ]
    }
   ],
   "source": [
    "train(model, False, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    n_iter_test_per_epoch = mnist.test.num_examples // batch_size\n",
    "\n",
    "    loss_test_ep = []\n",
    "    acc_test_ep  = []\n",
    "    #init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        #init.run()\n",
    "        #saver = tf.train.import_meta_graph(checkpoint_file +'.meta')\n",
    "        saver.restore(sess, tf.train.latest_checkpoint('tmp/'))\n",
    "\n",
    "        #init.run()\n",
    "        print('\\n\\nTest\\n')\n",
    "        for it in range(1, n_iter_test_per_epoch + 1):\n",
    "            X_batch, y_batch = mnist.test.next_batch(batch_size)\n",
    "            loss_batch_test, acc_batch_test = sess.run(\n",
    "                                [model.batch_loss, model.accuracy],\n",
    "                                feed_dict = { model.X_cropped: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                                    model.y: y_batch,\n",
    "                                    model.reconstruction: False})\n",
    "\n",
    "            loss_test_ep.append(loss_batch_test)\n",
    "            acc_test_ep.append(acc_batch_test)\n",
    "            print(\"\\rTesting {}/{} {:.1f}%\".format(it,\n",
    "                                            n_iter_test_per_epoch,\n",
    "                                            100.0 * it / n_iter_test_per_epoch),\n",
    "                                            end=\" \"*30)\n",
    "\n",
    "        loss_test = np.mean(loss_test_ep)\n",
    "        acc_test  = np.mean(acc_test_ep)\n",
    "\n",
    "        print(\"\\r(Testing) accuracy: {:.3f}%, loss: {:.4f}\".format(acc_test*100.0, loss_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from tmp/model.ckpt\n",
      "\n",
      "\n",
      "Test\n",
      "\n",
      "(Testing) accuracy: 99.640%, loss: 0.0116           \n"
     ]
    }
   ],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\r\n",
      "Your branch and 'origin/master' have diverged,\r\n",
      "and have 1 and 1 different commits each, respectively.\r\n",
      "  (use \"git pull\" to merge the remote branch into yours)\r\n",
      "You have unmerged paths.\r\n",
      "  (fix conflicts and run \"git commit\")\r\n",
      "  (use \"git merge --abort\" to abort the merge)\r\n",
      "\r\n",
      "Changes to be committed:\r\n",
      "\r\n",
      "\t\u001b[32mmodified:   capsules.py\u001b[m\r\n",
      "\t\u001b[32mmodified:   main.py\u001b[m\r\n",
      "\r\n",
      "Unmerged paths:\r\n",
      "  (use \"git add <file>...\" to mark resolution)\r\n",
      "\r\n",
      "\t\u001b[31mboth modified:   capsnet-nb.ipynb\u001b[m\r\n",
      "\t\u001b[31mboth modified:   capsnet.py\u001b[m\r\n",
      "\r\n",
      "Untracked files:\r\n",
      "  (use \"git add <file>...\" to include in what will be committed)\r\n",
      "\r\n",
      "\t\u001b[31mtest-nb.ipynb\u001b[m\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
