{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from capsnet import CapsNet\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data/')\n",
    "batch_size = 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "tf.random.set_random_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "checkpoint_file = './tmp/model.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "def count_params():\n",
    "    size = lambda v: functools.reduce(lambda x, y: x*y, v.get_shape().as_list())\n",
    "    n_trainable = sum(size(v) for v in tf.trainable_variables())\n",
    "    print(\"Model size (Trainable): {:.1f}M\\n\".format(n_trainable/1000000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, restore = False, n_epochs = 50):\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    n_iter_train_per_epoch = mnist.train.num_examples // batch_size\n",
    "    n_iter_valid_per_epoch = mnist.validation.num_examples // batch_size\n",
    "    n_iter_test_per_epoch  = mnist.test.num_examples // batch_size\n",
    "\n",
    "    best_loss_val = np.infty\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        writer = tf.summary.FileWriter(\"output\", sess.graph)\n",
    "\n",
    "        if restore and tf.train.checkpoint_exists('checkpoint_file'):\n",
    "            saver.restore(sess, checkpoint_file)\n",
    "        else:\n",
    "            init.run()\n",
    "\n",
    "        print('\\n\\nRunning CapsNet ...\\n')\n",
    "        count_params()\n",
    "\n",
    "        print(\"\\ntr_loss\\t: training loss\")\n",
    "        print(\"tr_ml       : training margin loss\")\n",
    "        print(\"tr_rl       : training reconstruction loss\")\n",
    "        print(\"v_loss      : validation loss\")\n",
    "        print(\"tr_acc      : training accuracy(%)\")\n",
    "        print(\"v_acc       : validation accuracy(%)\")\n",
    "        print(\"te_acc      : test accuracy(%)\\n\")\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            loss_train_ep = []\n",
    "            margin_loss_train_ep = []\n",
    "            recnst_loss_train_ep = []\n",
    "            acc_train_ep  = []\n",
    "            for it in range(1, n_iter_train_per_epoch + 1):\n",
    "                X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "                \n",
    "                _, loss_batch_train, margin_loss_train, recnst_loss_train, acc_batch_train = sess.run(\n",
    "                                [model.train_op, \n",
    "                                 model.batch_loss, \n",
    "                                 model.margn_loss,\n",
    "                                 model.recnst_loss_scale,\n",
    "                                 model.accuracy],\n",
    "                                feed_dict = {model.X: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                                             model.y: y_batch,\n",
    "                                             model.reconstruction: True})\n",
    "\n",
    "                print(\"\\rIter: {}/{} [{:.1f}%] loss : {:.5f}\".format(\n",
    "                    it, n_iter_train_per_epoch, 100.0 * it / n_iter_train_per_epoch, loss_batch_train), end=\"\")\n",
    "\n",
    "                loss_train_ep.append(loss_batch_train)\n",
    "                margin_loss_train_ep.append(margin_loss_train)\n",
    "                recnst_loss_train_ep.append(recnst_loss_train)\n",
    "                acc_train_ep.append(acc_batch_train)\n",
    "                \n",
    "            loss_train = np.mean(loss_train_ep)\n",
    "            margin_loss_train = np.mean(margin_loss_train_ep)\n",
    "            recnst_loss_train = np.mean(recnst_loss_train_ep)\n",
    "            acc_train = np.mean(acc_train_ep)\n",
    "            \n",
    "            loss_val_ep = []\n",
    "            acc_val_ep  = []\n",
    "\n",
    "            for it in range(1, n_iter_valid_per_epoch + 1):\n",
    "                X_batch, y_batch = mnist.validation.next_batch(batch_size)\n",
    "                loss_batch_val, acc_batch_val = sess.run(\n",
    "                                [model.batch_loss, model.accuracy],\n",
    "                                feed_dict = {model.X_cropped: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                                             model.y: y_batch,\n",
    "                                             model.reconstruction: False})\n",
    "\n",
    "                loss_val_ep.append(loss_batch_val)\n",
    "                acc_val_ep.append(acc_batch_val)\n",
    "\n",
    "                print(\"\\rValidation {}/{} {:.1f}%\".format(it, n_iter_valid_per_epoch, 100.0 * it / n_iter_valid_per_epoch), end=\" \"*30)\n",
    "\n",
    "            loss_val = np.mean(loss_val_ep)\n",
    "            acc_val  = np.mean(acc_val_ep)\n",
    "            \n",
    "            acc_test_ep  = []\n",
    "            \n",
    "            for it in range(1, n_iter_test_per_epoch + 1):\n",
    "                X_batch, y_batch = mnist.test.next_batch(batch_size)\n",
    "                acc_batch_test = sess.run(model.accuracy,\n",
    "                                    feed_dict = { model.X_cropped: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                                        model.y: y_batch,\n",
    "                                        model.reconstruction: False})\n",
    "                acc_test_ep.append(acc_batch_test)\n",
    "                \n",
    "                print(\"\\rTesting {}/{} {:.1f}%\".format(it, n_iter_test_per_epoch, 100.0 * it / n_iter_test_per_epoch), end=\" \"*30)\n",
    "                \n",
    "            acc_test  = np.mean(acc_test_ep)\n",
    "            \n",
    "            print(\"\\rEp {:2d}: tr_loss:{:.4f}, tr_ml:{:.4f}, tr_rl:{:.4f}, v_loss:{:.4f}, tr_acc:{:.3f}, v_acc:{:.2f}, te_acc: {:.2f}\".format(\n",
    "                epoch + 1, \n",
    "                loss_train, \n",
    "                margin_loss_train,\n",
    "                recnst_loss_train,\n",
    "                loss_val, \n",
    "                acc_train * 100.0, \n",
    "                acc_val * 100.0, \n",
    "                acc_test * 100.0))\n",
    "\n",
    "            saver.save(sess, checkpoint_file)\n",
    "            \n",
    "\n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "batch_size = 125\n",
    "model = CapsNet(rounds = 3, alpha = 0.0001, batch_size=batch_size, reconstruction_net = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, False, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
